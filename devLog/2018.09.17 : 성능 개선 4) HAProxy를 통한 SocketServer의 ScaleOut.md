# 16_DNA 프로젝트_매일매일 개발 일지

#### 2018.09.16 : ```성능 개선 4) HAProxy를 통한 SocketServer의 ScaleOut```

마지막 구조 개선으로, **소켓 서버**를 Scale-out 하기로 했습니다. **소켓 서버**의 경우 클라이언트와 소켓으로 연결되어 실시간으로 데이터를 주고 받아야 하기 때문에, 일반 ```HTTP``` 통신보다 더 많은 오버헤드를 필요로 합니다. 

개인적으로 서버개발캠프에서 Scale-out을 제대로 해보지 못한 점이 마음에 걸려왔는데, 이 참에 해봐야겠다! 싶어 많은 부하가 예상되는 **소켓 서버**에 적용해보기로 했습니다.



- **개발하면서 공부한 내용**

  - **스케일 업과 스케일 아웃**

    - 스케일 업 : 서버 자체를 고성능 장비로 대체해 처리 능력을 향상 시키는 것 (더 좋은 CPU를 쓰는 등...)

      프로그램 코드를 다시 작성하거나 아키텍처를 변경할 필요는 없지만, 비용이 많이 발생한다.

    - 스케일 아웃 : 서버의 대 수를 늘려 처리 능력을 향상 시키는 것 

      저렴한 서버를 다수로 구성해 비용이 절감되고, 특정 노드가 죽었을 때 전체 서비스에 장애가 발생하는 일을 막을 수 있다는 장점이 있다.

      하지만 분산 처리에 대한 경험이 필요하고, 프로그램 코드를 다시 작성할 필요가 생길 수 있다.

      

  - **HAProxy**

    - **로드 밸런싱** : 부하 분산을 위해 가상 IP를 통해 여러 서버에 접속하도록 분배하는 기능

    - HAProxy는 ```reverse proxy``` 형태로 동작한다. 이는 실제 서버 요청에 대해, 해당 서버 앞 단에 존재하면서 서버로 들어오는 요청을 대신 받아 서버에 전달하고 요청한 곳에 그 결과를 다시 전달하는 것을 말한다.

    - HAProxy의 동작 흐름은 다음과 같다.

      ```
      최초 접근 시 서버에 요청 전달
      응답 시 쿠키(cookie)에 서버 정보 추가 후 반환
      재요청 시 proxy에서 쿠키 정보 확인 > 최초 요청 서버로 전달
      다시 접근 시 쿠키 추가 없이 전달 > 클라이언트에 쿠키 정보가 계속 존재함(쿠키 재사용)
      ```

      참고 문헌 : [L4/L7 스위치의 대안, 오픈 소스 로드 밸런서 HAProxy](https://d2.naver.com/helloworld/284659)

      

___

- **어려웠던 점**

먼저 ```HAProxy```를 통해 여러 대의 **소켓 서버**로 유저의 요청을 전달하는 부분부터 구현해야 했습니다. 이 과정에서 어려웠던 점은 배포 상황에서는 좀 더 복잡했다는 것이었습니다. 로컬에서는 비교적 간단했지만, 배포할 때는 ```https``` 환경으로 요청을 주고 받을 수 있어야 했습니다. 다음은 ```HAProxy``` 설정 파일의 내용입니다.

```javascript
frontend wwws
	    bind		    0.0.0.0:{port}	ssl crt /etc/haproxy/certs/dna.soyoungpark.me
	    timeout client	1h	
        default_backend www_backend

        acl             is_websocket hdr(Upgrade) -i WebSocket
        use_backend     websocket_backend if is_websocket

backend www_backend
        mode            http
        stats           enable
        stats uri       /haproxy

        option forwardfor
        balance roundrobin
	    reqadd       x-forwarded-proto:\ https

        server server1 127.0.0.1:{port1} weight 1 maxconn 8192 check
        server server2 127.0.0.1:{port2} weight 1 maxconn 8192 check

backend websocket_backend
        mode            http

        option forwardfor
        option http-server-close
        option forceclose
        no option httpclose
        balance leastconn
	    reqadd       x-forwarded-proto:\ https

        server server1 127.0.0.1:{port1} weight 1 maxconn 8192 check
        server server2 127.0.0.1:{port2} weight 1 maxconn 8192 check
```

먼저 ```{port}```로 요청이 들어오면, 주어진 ```ssl``` 환경을 이용해 ```https``` 환경을 구축합니다. 그리고 해당 요청이 ```websocket```인지 아닌지 확인해, 맞을 경우에는 ```websocket_backend```로, 일반 ```HTTP``` 요청일 경우에는 ```www_backend```로 요청을 전송합니다. 그리고 server에 배포된 **소켓 서버**들의 포트를 입력해주면 끝!

이렇게 다수의 **소켓 서버**를 ```HAProxy```를 이용해 병렬적으로 사용하는 데까지는 구현이 완료되었지만, 남아 있는 일이 있었습니다. 바로 서버 간의 **동기화** 문제였습니다. 유저는 각 서버에 골고루 분배되어 클라이언트와 연결되게 되는데, 이로 인해 A서버와 연결된 클라이언트는 B서버에 연결된 클라이언트와 실시간으로 통신할 수 없다는 문제가 생겼습니다.



이를 해결하기 위해서 ```redis```의 **Pub/Sub** 기능을 사용했습니다.

- **초기 설정**

```javascript
// 서버간 pub/sub을 위해 socket 구독
sub.subscribe('socket');
```

먼저 서버가 Pub/Sub 기능을 이용할 수 있도록, ```socket``` 채널에 대한 구독을 시작합니다.

- **Publish**

```javascript
pub.publish('socket', JSON.stringify(data));
```

서버 내에 해당 클라이언트와 연결된 소켓이 없을 경우에는, ```socket```이라는 이름의 채널으로 **publish** 해 줍니다. 이 때, 전송할 메시지에 대한 데이터를 함께 보내줘야 합니다.

- **Subscribe**

```javascript
sub.on('message', (channel, data) => {
    const parsed = JSON.parse(data);

    if (channel === 'socket') {
      // 여기에 들어왔다는 것은, 메시지가 도착했는데 소켓이 그 서버에는 없었다는 뜻입니다.
      // 동시에 다른 서버에도 pub을 했을 테니까... 
      // 여기서도 똑같이 있으면 처리하고, 대신 없으면 다시 pub 해줄 필요없이 무시합니다.
      if (Object.keys(io.sockets.sockets).includes(parsed.socketId)) {
        io.sockets.to(parsed.socketId).emit(parsed.event, parsed.response);
      }      
    }
});
```

마지막으로, 모든 서버가 ```socket``` 채널으로 전송되는 메시지들에 대해 구독하도록 합니다. 해당 메시지가 발행된 것은, 특정 서버에 메시지가 도착했는데 소켓이 해당 서버에 없었다는 의미입니다. 따라서 해당 서버의 소켓 리스트에 타겟이 되는 클라이언트가 있는지 확인하고, 있다면 그 서버로 이벤트를 전송해줍니다.



____

- **회고**

여러 대의 서버를 띄워 두고, ```HAProxy```에 의해 요청이 각 서버에 골고루 들어오는 것을 보니 굉장히 신기했습니다! Scale Out에 대한 개념을 어렴풋이나마 잡을 수 있었던 경험이었습니다. 이제 졸업 작품은 더 이상 손을 대지 않을 것 같지만... 추후 더 개선할 사항이 생기면 다시 시작하는 걸로! ~~(그럴 일은 없으면 좋겠...다..)~~